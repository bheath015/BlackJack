PLAN: 
I took the approach of attempting to find the optimal threshold for a human player to stop hitting. If we assume Aces to be 1 as they likely will be once we hit after the first draw (and to be conservative in our strategy), we know that the average card in a deck is worth 6.54 points. Rounding this to 7, I would assume that our best bet to win consistently would be to hit at any point when the human hand is less than 21-7, or 14. My Monte Carlo simulation runs in this way, and we keep the computer’s rules the same (hitting until they reach 17 points). My advantage is that the chance of my hits causing me to bust are less than that of the computer. The computer maintains somewhat of an advantage as well because they do not have to make a move until I do. 

README: 
Please refer to the other readme file to understand the the structure of the game. I will point out the differences below.

1) The BankerMC class maintains five new variables: trials, p1WinCount, c1WinCount, pushCount, and errorCount. Trials will be received in the constructor and will indicate the number of times that the Monte Carlo simulation will play the games. The other variables track the number of human wins, computer wins, pushes, and errors respectively (hopefully errors = 0). The new getResults() method prints the totals of these four variables. There is no longer any communication with the user until the totals are computed at the end. We now initialize decks, hands, and players locally so that they reset each game. 

2) The HumanPlayerMC class no longer interacts with a user but has a rigid betting strategy- hit while the score is under 14 and stand at and above 14. The human player will optimize its score as before taking into account the fact that aces can be 1 or 11. 

3) BlackJackTesterMC takes in the number of trials when it establishes a Banker object and retrieves the totals.

CONCLUSIONS:
As it turns out, I was not born to gamble. During multiple 1000-trial experiments, the human won between 50-110 fewer times than the computer (for example, in one round h1WinCount=415, c1WinCount=516, pushCount=69, errorCount = 0). I guess in hindsight I am not surprised that this did not work. There is valuable information that one could take into account by looking at the computer’s card. The other issue is that we do not know if the human player’s strategy is necessarily worse than the computer’s strategy; it is possible that this is a better strategy but the computer continues to win more often because they never actually have to execute their strategy any time the human busts. I guess this signals the not-so-romantic end to a short-lived gambling career. 